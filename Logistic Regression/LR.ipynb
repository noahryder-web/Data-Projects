{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69e58654-305a-4815-b7b0-eea9f2f035f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import  PartialDependenceDisplay,permutation_importance\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn import tree\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('day.csv')\n",
    "\n",
    "# Select relevant features and target\n",
    "features = ['hum','temp', 'windspeed']\n",
    "target = 'cnt'\n",
    "X = data.loc[:,'season':'windspeed']\n",
    "y = data['cnt']>=data['cnt'].median()  # Target is count of bike rentals\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)\n",
    "X_test_scaled= pd.DataFrame(scaler.transform(X_test), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4d93b7f-767a-4657-9a4a-382da24ff742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -0.007\n",
      "hum_s: 0.831\n",
      "temp_s: 1.883\n",
      "windspeed_s: 0.089\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f'Intercept: {log_reg.intercept_[0]:.3f}')\n",
    "for coef, feature in zip(log_reg.coef_[0], features):\n",
    "    print(f'{feature}_s: {coef:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5fc6f7c-c6c0-4a7b-9219-2c40c0fecd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hum odds ratio: 2.296\n",
      "temp odds ratio: 6.576\n",
      "windspeed odds ratio: 1.093\n"
     ]
    }
   ],
   "source": [
    "def coefficients_to_odds_ratios(coefficients):\n",
    "    \n",
    "    \"\"\"\n",
    "    Convert logistic regression coefficients to odds ratios.\n",
    "    \n",
    "    Parameters:\n",
    "        coefficients (array-like): Array of logistic regression coefficients\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Array of odds ratios\n",
    "    \n",
    "    Example:\n",
    "        >>> coefficients_to_odds_ratios([0.693, -0.693])\n",
    "        array([2.0, 0.5])  # e^0.693 ≈ 2.0, e^-0.693 ≈ 0.5\n",
    "    \"\"\"\n",
    "    coefficients = np.array(coefficients)\n",
    "    return np.exp(coefficients)\n",
    "\n",
    "# Test with basic model\n",
    "basic_odds_ratios = coefficients_to_odds_ratios(log_reg.coef_[0])\n",
    "for feature, odds_ratio in zip(features, basic_odds_ratios):\n",
    "    print(f\"{feature} odds ratio: {odds_ratio:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aa42b1d-167e-412e-8b3a-e39ca9ab6880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hum probability change: 0.197\n",
      "temp probability change: 0.368\n",
      "windspeed probability change: 0.022\n"
     ]
    }
   ],
   "source": [
    "def probability_change_at_mean(coefficient):\n",
    "    \"\"\"\n",
    "    Calculate the change in probability at the mean (P=0.5) for a given coefficient.\n",
    "    \n",
    "    Parameters:\n",
    "        coefficient (float): Logistic regression coefficient\n",
    "        \n",
    "    Returns:\n",
    "        float: Change in probability (between -0.5 and 0.5)\n",
    "    \n",
    "    Example:\n",
    "        >>> probability_change_at_mean(0.693)\n",
    "        0.167  # Approximately 16.7 percentage point increase\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-coefficient)) - 0.5\n",
    "\n",
    "# Test with our basic model\n",
    "for feature, coef in zip(features, log_reg.coef_[0]):\n",
    "    prob_change = probability_change_at_mean(coef)\n",
    "    print(f\"{feature} probability change: {prob_change:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac7f11a-8172-43e8-a4da-ce15841ea537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic Model Interpretation:\n",
      "\n",
      "hum:\n",
      "  coefficient: 0.831\n",
      "  odds_ratio: 2.296\n",
      "  probability_change: 0.197\n",
      "\n",
      "temp:\n",
      "  coefficient: 1.883\n",
      "  odds_ratio: 6.576\n",
      "  probability_change: 0.368\n",
      "\n",
      "windspeed:\n",
      "  coefficient: 0.089\n",
      "  odds_ratio: 1.093\n",
      "  probability_change: 0.022\n",
      "\n",
      "Expanded Model Interpretation (first 3 features):\n",
      "\n",
      "hum:\n",
      "  coefficient: -0.820\n",
      "  odds_ratio: 0.441\n",
      "  probability_change: -0.194\n",
      "\n",
      "temp:\n",
      "  coefficient: 1.434\n",
      "  odds_ratio: 4.196\n",
      "  probability_change: 0.308\n",
      "\n",
      "windspeed:\n",
      "  coefficient: -0.425\n",
      "  odds_ratio: 0.654\n",
      "  probability_change: -0.105\n"
     ]
    }
   ],
   "source": [
    "expanded_features =features + ['season', 'holiday', 'weekday']\n",
    "expanded_model = LogisticRegression(random_state=42)\n",
    "expanded_model.fit(X_train_scaled[expanded_features], y_train)\n",
    "\n",
    "def interpret_logistic_model(model, feature_names):\n",
    "    # Get coefficients from model\n",
    "    coefficients = model.coef_[0]\n",
    "    \n",
    "    # Calculate interpretability metrics\n",
    "    odds_ratios = coefficients_to_odds_ratios(coefficients)\n",
    "    prob_changes = np.array([probability_change_at_mean(coef) for coef in coefficients])\n",
    "    \n",
    "    # Create interpretation dictionary\n",
    "    interpretation = {}\n",
    "    for idx, feature in enumerate(feature_names):\n",
    "        interpretation[feature] = {\n",
    "            'coefficient': coefficients[idx],\n",
    "            'odds_ratio': odds_ratios[idx],\n",
    "            'probability_change': prob_changes[idx]\n",
    "        }\n",
    "    \n",
    "    return interpretation\n",
    "\n",
    "# Compare interpretations\n",
    "print(\"\\nBasic Model Interpretation:\")\n",
    "basic_interpretation = interpret_logistic_model(log_reg,features)\n",
    "for feature, metrics in basic_interpretation.items():\n",
    "    print(f\"\\n{feature}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.3f}\")\n",
    "\n",
    "print(\"\\nExpanded Model Interpretation (first 3 features):\")\n",
    "expanded_interpretation = interpret_logistic_model(\n",
    "    expanded_model, \n",
    "    expanded_features\n",
    ")\n",
    "for feature in features:\n",
    "    print(f\"\\n{feature}:\")\n",
    "    for metric, value in expanded_interpretation[feature].items():\n",
    "        print(f\"  {metric}: {value:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
